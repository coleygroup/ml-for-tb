{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using chemprop version 1.6.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import errno\n",
    "import chemprop\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "print(f\"Using chemprop version {chemprop.__version__}\")\n",
    "\n",
    "from sklearn.metrics import f1_score, average_precision_score, roc_auc_score\n",
    "\n",
    "from typing import Dict, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.data_dir = '../data'\n",
    "        self.dataset = 'taacf'\n",
    "        self.smiles_col = 'smiles'\n",
    "        self.target_col = 'auc_bin' if self.dataset == 'pk' else 'inhibition_bin'\n",
    "        self.use_gpu = True\n",
    "        self.train_batch_size = 1048\n",
    "        self.infer_batch_size = 1048\n",
    "\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already exists. Skipping.\n"
     ]
    }
   ],
   "source": [
    "def make_dmpnn_dataset(args):\n",
    "    df_trn = pd.read_csv(f\"{args.data_dir}/{args.dataset}/{args.dataset}_trn.csv\")\n",
    "    df_val = pd.read_csv(f\"{args.data_dir}/{args.dataset}/{args.dataset}_val.csv\")\n",
    "    df_tst = pd.read_csv(f\"{args.data_dir}/{args.dataset}/{args.dataset}_tst.csv\")\n",
    "\n",
    "    df_trn_ = df_trn[[args.smiles_col, args.target_col]]\n",
    "    df_val_ = df_val[[args.smiles_col, args.target_col]]\n",
    "    df_tst_ = df_tst[[args.smiles_col, args.target_col]]\n",
    "\n",
    "    df_trn_val_ = pd.concat([df_trn_, df_val_])\n",
    "\n",
    "    df_trn_val_.to_csv(f\"{args.data_dir}/{args.dataset}/{args.dataset}_dmpnn_trn.csv\")\n",
    "    df_tst_.to_csv(f\"{args.data_dir}/{args.dataset}/{args.dataset}_dmpnn_tst.csv\")\n",
    "\n",
    "if not os.path.exists(f\"{args.data_dir}/{args.dataset}/{args.dataset}_dmpnn_trn.csv\"):\n",
    "    print(\"Making dataset.\")\n",
    "    make_dmpnn_dataset(args)\n",
    "    print(\"Done.\")\n",
    "else:\n",
    "    print(f\"Dataset already exists. Skipping.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_params(params_dict: Dict[str, str]) -> List[str]:\n",
    "    params_list = []\n",
    "    for k, v in params_dict.items():\n",
    "        params_list.append(f\"--{k}\")\n",
    "        if v != 'None':\n",
    "            params_list.append(v)\n",
    "    return params_list\n",
    "\n",
    "def load_mpnn_config(args):\n",
    "\n",
    "    config_path = f\"{args.data_dir}/configs/{args.dataset}_D-MPNN_config.json\"\n",
    "    \n",
    "    optim_data_path = f\"{args.data_dir}/{args.dataset}/{args.dataset}_dmpnn_trn.csv\"\n",
    "    optim_config_save_path = f\"{args.data_dir}/configs/{args.dataset}_D-MPNN_config_new.json\"\n",
    "    \n",
    "    train_data_path = optim_data_path\n",
    "    train_ckpt_dir = f\"{args.data_dir}/checkpoints\"\n",
    "\n",
    "    test_data_path = f\"{args.data_dir}/{args.dataset}/{args.dataset}_dmpnn_tst.csv\"\n",
    "    test_preds_path = f\"{args.data_dir}/{args.dataset}/{args.dataset}_dmpnn_tst_preds.csv\"\n",
    "    test_ckpt_dir = train_ckpt_dir\n",
    "\n",
    "    if os.path.exists(config_path):\n",
    "        with open(config_path, 'r') as f:\n",
    "            config = json.load(f)\n",
    "    else:\n",
    "        raise FileNotFoundError(errno.ENOENT, os.strerror(errno.ENOENT), config_path)\n",
    "\n",
    "    config['optim']['data_path'] = optim_data_path\n",
    "    config['optim']['config_save_path'] = optim_config_save_path\n",
    "\n",
    "    config['train']['data_path'] = train_data_path\n",
    "    config['train']['save_dir'] = train_ckpt_dir\n",
    "\n",
    "    config['test']['test_path'] = test_data_path\n",
    "    config['test']['preds_path'] = test_preds_path\n",
    "    config['test']['checkpoint_dir'] = test_ckpt_dir\n",
    "\n",
    "    for k in ['optim', 'train', 'test']:\n",
    "        config[k]['smiles_column'] = args.smiles_col\n",
    "        if k != 'test':\n",
    "            config[k]['target_columns'] = args.target_col\n",
    "\n",
    "    config['train']['batch_size'] = str(args.train_batch_size)\n",
    "    config['test']['batch_size'] = str(args.infer_batch_size)\n",
    "\n",
    "    config['train']['num_workers'] = '7'\n",
    "    config['test']['num_workers'] = '7'\n",
    "\n",
    "    return config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = load_mpnn_config(args)\n",
    "trn_params = make_params(params['train'])\n",
    "tst_params = make_params(params['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Command line\n",
      "python /Users/vedang/miniconda3/envs/metal2/lib/python3.10/site-packages/ipykernel_launcher.py --f=/Users/vedang/Library/Jupyter/runtime/kernel-v2-7735xZBxa0fHsTHu.json\n",
      "Args\n",
      "{'activation': 'ReLU',\n",
      " 'adding_bond_types': True,\n",
      " 'adding_h': False,\n",
      " 'aggregation': 'mean',\n",
      " 'aggregation_norm': 100,\n",
      " 'atom_constraints': [],\n",
      " 'atom_descriptor_scaling': True,\n",
      " 'atom_descriptors': None,\n",
      " 'atom_descriptors_path': None,\n",
      " 'atom_descriptors_size': 0,\n",
      " 'atom_features_size': 0,\n",
      " 'atom_messages': False,\n",
      " 'atom_targets': [],\n",
      " 'batch_size': 1048,\n",
      " 'bias': False,\n",
      " 'bias_solvent': False,\n",
      " 'bond_constraints': [],\n",
      " 'bond_descriptor_scaling': True,\n",
      " 'bond_descriptors': None,\n",
      " 'bond_descriptors_path': None,\n",
      " 'bond_descriptors_size': 0,\n",
      " 'bond_features_size': 0,\n",
      " 'bond_targets': [],\n",
      " 'cache_cutoff': 10000,\n",
      " 'checkpoint_dir': None,\n",
      " 'checkpoint_frzn': None,\n",
      " 'checkpoint_path': None,\n",
      " 'checkpoint_paths': None,\n",
      " 'class_balance': True,\n",
      " 'config_path': None,\n",
      " 'constraints_path': None,\n",
      " 'crossval_index_dir': None,\n",
      " 'crossval_index_file': None,\n",
      " 'crossval_index_sets': None,\n",
      " 'cuda': False,\n",
      " 'data_path': '../data/taacf/taacf_dmpnn_trn.csv',\n",
      " 'data_weights_path': None,\n",
      " 'dataset_type': 'classification',\n",
      " 'depth': 4,\n",
      " 'depth_solvent': 3,\n",
      " 'device': device(type='cpu'),\n",
      " 'dropout': 0.05,\n",
      " 'empty_cache': False,\n",
      " 'ensemble_size': 1,\n",
      " 'epochs': 600,\n",
      " 'evidential_regularization': 0,\n",
      " 'explicit_h': False,\n",
      " 'extra_metrics': ['f1'],\n",
      " 'features_generator': None,\n",
      " 'features_only': False,\n",
      " 'features_path': None,\n",
      " 'features_scaling': True,\n",
      " 'features_size': None,\n",
      " 'ffn_hidden_size': 500,\n",
      " 'ffn_num_layers': 1,\n",
      " 'final_lr': 0.0001,\n",
      " 'folds_file': None,\n",
      " 'freeze_first_only': False,\n",
      " 'frzn_ffn_layers': 0,\n",
      " 'gpu': None,\n",
      " 'grad_clip': None,\n",
      " 'hidden_size': 300,\n",
      " 'hidden_size_solvent': 300,\n",
      " 'ignore_columns': None,\n",
      " 'init_lr': 0.0001,\n",
      " 'is_atom_bond_targets': False,\n",
      " 'keeping_atom_map': False,\n",
      " 'log_frequency': 10,\n",
      " 'loss_function': 'binary_cross_entropy',\n",
      " 'max_data_size': None,\n",
      " 'max_lr': 0.001,\n",
      " 'metric': 'binary_cross_entropy',\n",
      " 'metrics': ['binary_cross_entropy', 'f1'],\n",
      " 'minimize_score': True,\n",
      " 'mpn_shared': False,\n",
      " 'multiclass_num_classes': 3,\n",
      " 'no_adding_bond_types': False,\n",
      " 'no_atom_descriptor_scaling': False,\n",
      " 'no_bond_descriptor_scaling': False,\n",
      " 'no_cache_mol': False,\n",
      " 'no_cuda': False,\n",
      " 'no_features_scaling': False,\n",
      " 'no_shared_atom_bond_ffn': False,\n",
      " 'num_folds': 1,\n",
      " 'num_lrs': 1,\n",
      " 'num_tasks': 1,\n",
      " 'num_workers': 7,\n",
      " 'number_of_molecules': 1,\n",
      " 'overwrite_default_atom_features': False,\n",
      " 'overwrite_default_bond_features': False,\n",
      " 'phase_features_path': None,\n",
      " 'pytorch_seed': 0,\n",
      " 'quiet': False,\n",
      " 'reaction': False,\n",
      " 'reaction_mode': 'reac_diff',\n",
      " 'reaction_solvent': False,\n",
      " 'resume_experiment': False,\n",
      " 'save_dir': '../data/checkpoints',\n",
      " 'save_preds': False,\n",
      " 'save_smiles_splits': False,\n",
      " 'seed': 42,\n",
      " 'separate_test_atom_descriptors_path': None,\n",
      " 'separate_test_bond_descriptors_path': None,\n",
      " 'separate_test_constraints_path': None,\n",
      " 'separate_test_features_path': None,\n",
      " 'separate_test_path': None,\n",
      " 'separate_test_phase_features_path': None,\n",
      " 'separate_val_atom_descriptors_path': None,\n",
      " 'separate_val_bond_descriptors_path': None,\n",
      " 'separate_val_constraints_path': None,\n",
      " 'separate_val_features_path': None,\n",
      " 'separate_val_path': None,\n",
      " 'separate_val_phase_features_path': None,\n",
      " 'shared_atom_bond_ffn': True,\n",
      " 'show_individual_scores': False,\n",
      " 'smiles_columns': ['smiles'],\n",
      " 'spectra_activation': 'exp',\n",
      " 'spectra_phase_mask_path': None,\n",
      " 'spectra_target_floor': 1e-08,\n",
      " 'split_key_molecule': 0,\n",
      " 'split_sizes': [0.8, 0.1, 0.1],\n",
      " 'split_type': 'random',\n",
      " 'target_columns': ['inhibition_bin'],\n",
      " 'target_weights': None,\n",
      " 'task_names': ['inhibition_bin'],\n",
      " 'test': False,\n",
      " 'test_fold_index': None,\n",
      " 'train_data_size': None,\n",
      " 'undirected': False,\n",
      " 'use_input_features': False,\n",
      " 'val_fold_index': None,\n",
      " 'warmup_epochs': 2.0,\n",
      " 'weights_ffn_num_layers': 2}\n",
      "Setting molecule featurization parameters to default.\n",
      "Loading data\n",
      "43266it [00:00, 432607.81it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x127507b50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/vedang/miniconda3/envs/metal2/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/Users/vedang/miniconda3/envs/metal2/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1437, in _shutdown_workers\n",
      "    if self._persistent_workers or self._workers_status[worker_id]:\n",
      "AttributeError: '_MultiProcessingDataLoaderIter' object has no attribute '_workers_status'\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Users/vedang/miniconda3/envs/metal2/lib/python3.10/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/Users/vedang/miniconda3/envs/metal2/lib/python3.10/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "_pickle.UnpicklingError: pickle data was truncated\n",
      "99275it [00:00, 115122.68it/s]\n",
      "100%|██████████| 99275/99275 [00:00<00:00, 153915.64it/s]\n",
      "100%|██████████| 99275/99275 [00:00<00:00, 123122.96it/s]\n",
      "Number of tasks = 1\n",
      "Fold 0\n",
      "Splitting data with seed 42\n",
      "Class sizes\n",
      "inhibition_bin 0: 97.58%, 1: 2.42%\n",
      "Total size = 99,275 | train size = 79,420 | val size = 9,927 | test size = 9,928\n",
      "With class_balance, effective train size = 3,896\n",
      "Building model 0\n",
      "MoleculeModel(\n",
      "  (sigmoid): Sigmoid()\n",
      "  (encoder): MPN(\n",
      "    (encoder): ModuleList(\n",
      "      (0): MPNEncoder(\n",
      "        (dropout): Dropout(p=0.05, inplace=False)\n",
      "        (act_func): ReLU()\n",
      "        (W_i): Linear(in_features=147, out_features=300, bias=False)\n",
      "        (W_h): Linear(in_features=300, out_features=300, bias=False)\n",
      "        (W_o): Linear(in_features=433, out_features=300, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (readout): Sequential(\n",
      "    (0): Dropout(p=0.05, inplace=False)\n",
      "    (1): Linear(in_features=300, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "Number of parameters = 264,901\n",
      "  0%|          | 0/600 [00:00<?, ?it/s]Epoch 0\n",
      "  0%|          | 0/600 [00:53<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m trn_args \u001b[38;5;241m=\u001b[39m chemprop\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mTrainArgs()\u001b[38;5;241m.\u001b[39mparse_args(trn_params)\n\u001b[0;32m----> 2\u001b[0m mean_score, std_score \u001b[38;5;241m=\u001b[39m \u001b[43mchemprop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrn_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchemprop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_training\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/metal2/lib/python3.10/site-packages/chemprop/utils.py:591\u001b[0m, in \u001b[0;36mtimeit.<locals>.timeit_decorator.<locals>.wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m    589\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrap\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    590\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time()\n\u001b[0;32m--> 591\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    592\u001b[0m     delta \u001b[38;5;241m=\u001b[39m timedelta(seconds\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mround\u001b[39m(time() \u001b[38;5;241m-\u001b[39m start_time))\n\u001b[1;32m    593\u001b[0m     info \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(logger_name)\u001b[38;5;241m.\u001b[39minfo \u001b[38;5;28;01mif\u001b[39;00m logger_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mprint\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/metal2/lib/python3.10/site-packages/chemprop/train/cross_validate.py:119\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(args, train_func)\u001b[0m\n\u001b[1;32m    116\u001b[0m         model_scores \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m    117\u001b[0m \u001b[38;5;66;03m# Otherwise, train the models\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 119\u001b[0m     model_scores \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m metric, scores \u001b[38;5;129;01min\u001b[39;00m model_scores\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    122\u001b[0m     all_scores[metric]\u001b[38;5;241m.\u001b[39mappend(scores)\n",
      "File \u001b[0;32m~/miniconda3/envs/metal2/lib/python3.10/site-packages/chemprop/train/run_training.py:295\u001b[0m, in \u001b[0;36mrun_training\u001b[0;34m(args, data, logger)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m trange(args\u001b[38;5;241m.\u001b[39mepochs):\n\u001b[1;32m    294\u001b[0m     debug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 295\u001b[0m     n_iter \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_data_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m        \u001b[49m\u001b[43matom_bond_scaler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43matom_bond_scaler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogger\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogger\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwriter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwriter\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    307\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(scheduler, ExponentialLR):\n\u001b[1;32m    308\u001b[0m         scheduler\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/miniconda3/envs/metal2/lib/python3.10/site-packages/chemprop/train/train.py:53\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, data_loader, loss_func, optimizer, scheduler, args, n_iter, atom_bond_scaler, logger, writer)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m     loss_sum \u001b[38;5;241m=\u001b[39m iter_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m tqdm(data_loader, total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(data_loader), leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;66;03m# Prepare batch\u001b[39;00m\n\u001b[1;32m     55\u001b[0m     batch: MoleculeDataset\n\u001b[1;32m     56\u001b[0m     mol_batch, features_batch, target_batch, mask_batch, atom_descriptors_batch, atom_features_batch, bond_descriptors_batch, bond_features_batch, constraints_batch, data_weights_batch \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m     57\u001b[0m         batch\u001b[38;5;241m.\u001b[39mbatch_graph(), batch\u001b[38;5;241m.\u001b[39mfeatures(), batch\u001b[38;5;241m.\u001b[39mtargets(), batch\u001b[38;5;241m.\u001b[39mmask(), batch\u001b[38;5;241m.\u001b[39matom_descriptors(), \\\n\u001b[1;32m     58\u001b[0m         batch\u001b[38;5;241m.\u001b[39matom_features(), batch\u001b[38;5;241m.\u001b[39mbond_descriptors(), batch\u001b[38;5;241m.\u001b[39mbond_features(), batch\u001b[38;5;241m.\u001b[39mconstraints(), batch\u001b[38;5;241m.\u001b[39mdata_weights()\n",
      "File \u001b[0;32m~/miniconda3/envs/metal2/lib/python3.10/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/metal2/lib/python3.10/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/metal2/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1318\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1315\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;66;03m# no valid `self._rcvd_idx` is found (i.e., didn't break)\u001b[39;00m\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_persistent_workers:\n\u001b[0;32m-> 1318\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_shutdown_workers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1319\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[1;32m   1321\u001b[0m \u001b[38;5;66;03m# Now `self._rcvd_idx` is the batch index we want to fetch\u001b[39;00m\n\u001b[1;32m   1322\u001b[0m \n\u001b[1;32m   1323\u001b[0m \u001b[38;5;66;03m# Check if the next sample has already been generated\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/metal2/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1443\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._shutdown_workers\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1438\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mark_worker_as_unavailable(worker_id, shutdown\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1439\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers:\n\u001b[1;32m   1440\u001b[0m     \u001b[38;5;66;03m# We should be able to join here, but in case anything went\u001b[39;00m\n\u001b[1;32m   1441\u001b[0m     \u001b[38;5;66;03m# wrong, we set a timeout and if the workers fail to join,\u001b[39;00m\n\u001b[1;32m   1442\u001b[0m     \u001b[38;5;66;03m# they are killed in the `finally` block.\u001b[39;00m\n\u001b[0;32m-> 1443\u001b[0m     \u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMP_STATUS_CHECK_INTERVAL\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1444\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m q \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_queues:\n\u001b[1;32m   1445\u001b[0m     q\u001b[38;5;241m.\u001b[39mcancel_join_thread()\n",
      "File \u001b[0;32m~/miniconda3/envs/metal2/lib/python3.10/multiprocessing/process.py:149\u001b[0m, in \u001b[0;36mBaseProcess.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent_pid \u001b[38;5;241m==\u001b[39m os\u001b[38;5;241m.\u001b[39mgetpid(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcan only join a child process\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcan only join a started process\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 149\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_popen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m     _children\u001b[38;5;241m.\u001b[39mdiscard(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/metal2/lib/python3.10/multiprocessing/popen_fork.py:40\u001b[0m, in \u001b[0;36mPopen.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmultiprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconnection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m wait\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msentinel\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     41\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# This shouldn't block if wait() returned successfully.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/metal2/lib/python3.10/multiprocessing/connection.py:931\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    928\u001b[0m     deadline \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 931\u001b[0m     ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n\u001b[1;32m    933\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [key\u001b[38;5;241m.\u001b[39mfileobj \u001b[38;5;28;01mfor\u001b[39;00m (key, events) \u001b[38;5;129;01min\u001b[39;00m ready]\n",
      "File \u001b[0;32m~/miniconda3/envs/metal2/lib/python3.10/selectors.py:416\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trn_args = chemprop.args.TrainArgs().parse_args(trn_params)\n",
    "mean_score, std_score = chemprop.train.cross_validate(args=trn_args, train_func=chemprop.train.run_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training args\n",
      "Setting molecule featurization parameters to default.\n",
      "Loading data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "38it [00:00, 64948.47it/s]\n",
      "100%|██████████| 38/38 [00:00<00:00, 72944.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating SMILES\n",
      "Test size = 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained parameter \"encoder.encoder.0.cached_zero_vector\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_i.weight\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_h.weight\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_o.weight\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_o.bias\".\n",
      "Loading pretrained parameter \"readout.1.weight\".\n",
      "Loading pretrained parameter \"readout.1.bias\".\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:13<00:00, 13.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving predictions to ../data/pk/pk_dmpnn_tst_preds.csv\n",
      "Elapsed time = 0:00:14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tst_args = chemprop.args.PredictArgs().parse_args(tst_params)\n",
    "y_preds = np.array(chemprop.train.make_predictions(args=tst_args)).reshape(-1)\n",
    "y_true = pd.read_csv(f\"{args.data_dir}/{args.dataset}/{args.dataset}_dmpnn_tst.csv\")[args.target_col].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_f1_score(y_true, y_score):\n",
    "    \"\"\" \n",
    "    Calculates the maximum possible F1 score given true labels and prob scores. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true: List[int] or np.array\n",
    "        True (binary) labels.\n",
    "    y_score: List[float] or np.array\n",
    "        Prob scores from the model.\n",
    "    \"\"\"\n",
    "    return max([f1_score(y_true, (np.array(y_score) > t).astype(int)) for t in np.arange(0., 1.01, 0.02)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_evaluation(y_true, y_preds):\n",
    "    print(f\"AUROC = {round(roc_auc_score(y_true, y_preds), 5)*100}\")\n",
    "    print(f\"AP = {round(average_precision_score(y_true, y_preds), 5)*100}\")\n",
    "    print(f\"Max. F1 score = {round(max_f1_score(y_true, y_preds), 5)*100}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metal2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
